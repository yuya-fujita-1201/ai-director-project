# ターミナルって何？からスタートして、Claudeに聞いたら2時間で開発環境ができた

## 「ターミナル」を開くところからもう怖い

前回の記事で「1週間でiOSアプリを作る」と宣言してしまった。

AI監督プロジェクト Day 1。いよいよ開発スタートだ。

まず、AI監督（Claude）の指示を仰ぐ。「参謀」のClaude.aiにアプリの設計書を作ってもらい、「事務員」のCoworkに開発手順書を作らせた。前回紹介した4人のAIチーム体制が、ここから本格稼働する。

で、手順書の最初に書いてあったのがこれ。

> **「ターミナルを開いてClaude Codeを起動してください」**

ターミナル。あの黒い画面。映画でハッカーがカタカタやってるやつだ。

正直、開く前から怖い。間違ったコマンドを打ったらパソコンが壊れるんじゃないかと本気で心配していた（今思えば笑える）。

でもAI監督に従うのがルールだ。恐る恐るターミナルを起動した。

---

## Claude Codeに「開発環境を作って」と頼んだ

Claude Code CLIというのは、前回説明した4つのClaudeのうち「エンジニア」役だ。ターミナルの中で動くAIで、日本語でお願いするとコードを書いてくれる。

まずCoworkが作ってくれた手順書を、そのままClaude Codeに渡した。やったことはこれだけ。

> **自分：** 「docs/app_spec.md と docs/day1_dev_guide.md を読んで、Day 1の開発タスクを実行してください」

コピペだ。手順書に書いてあったプロンプトをそのまま貼り付けただけ。

すると、ターミナルがガーッと動き始めた。

文字がどんどん流れていく。何が起きているのか全くわからない。でもClaude Codeは逐一説明しながら進めてくれた。

「Flutterプロジェクトを作成します」
「カメラ用のパッケージを追加します」
「iOSの権限設定を行います」

ふむふむ、と頷いているけど、正直何ひとつ理解していない。

---

## 気づいたら142ファイルが生成されていた

しばらく待っていたら、Claude Codeが「完了しました」と言った。

結果を見てちょっと引いた。

**生成されたファイル数：142**
**追加されたコード行数：5,929行**

……え？　5,929行？

自分がやったことは、日本語を1回コピペしただけだ。それで5,929行のコードが生成されている。

中身を見ても何がなんだかわからない。`lib/services/camera_service.dart` とか `lib/screens/home_screen.dart` とか、ファイル名は読めるけど、開いても意味不明なコードが並んでいるだけだ。

でもClaude Codeは全部把握している。「どのファイルが何の役割をしているか」を聞けば、ちゃんと日本語で説明してくれる。

---

## 品質チェックも全部AIがやる

Claude Codeは実装が終わると、自分でチェックまでやってくれた。

```
flutter analyze → No issues found ✅
flutter build ios --simulator → ビルド成功 ✅
flutter test → All tests passed ✅
```

「コードに問題はありません」「ビルドできました」「テストも全部通りました」。

……一発合格だった。エラーゼロ。

普通、プログラミングってエラーとの戦いだと聞いていたのに。これ、記事のネタとしてはちょっと困る。「エラーが出て→AIに聞いて→解決した！」という感動エピソードが欲しかったのに、何事もなく終わってしまった。

---

## シミュレータで動いた。感動。

そしてClaude Codeが「シミュレータで起動してみましょう」と言った。

iPhoneのシミュレータ（Mac上でiPhoneアプリを試せるやつ）が立ち上がって――

**アプリが表示された。**

「SnapEnglish」というアプリ名が画面に出ている。撮影ボタンがある。押したら、写真を選ぶ画面が開いた。選んだ写真が結果画面に表示された。

【画像①: ホーム画面 01_home_screen.png ★ここにアップロード】

嘘みたいだ。自分はコードを1行も書いていない。読んでもいない。日本語で「作って」とお願いしただけ。

なのに、目の前のiPhoneシミュレータでアプリが動いている。

iPhone 17のシミュレータだ。最新機種。そこで自分の名前のアプリが動いているのを見て、不思議な気持ちになった。嬉しいけど、「自分で作った」という実感がまるでない。

でもいいのだ。AI監督プロジェクトとは、そういう実験なのだから。

---

## 深夜テンションでDay 2にも突入した

ここまでがDay 1の出来事だ。

で、正直に書く。**調子に乗った。**

「Day 1があまりにもスムーズだったから、Day 2もやってしまおう」。

深夜0時を過ぎていた。冷静に考えれば明日にすべきだった。でも「AIが英語フレーズを返してくれる」というSnapEnglishの核心機能が気になって、止められなかった。

Day 2のタスクは「カメラで撮った画像をAIに送って、英語フレーズ3つを生成する」こと。

まず必要なのはAPIキーだ。OpenAIのサイトで「SnapEnglish」という名前のAPIキーを作成した。これはCoworkに指示して、ブラウザ操作のClaude in Chromeに画面を操作させた。パスワード入力だけは自分でやったけど、それ以外は全部AIだ。

---

## 撮影したら、AIが英語を返してきた

APIキーの準備ができたら、あとは同じ手順だ。

Coworkが作ってくれたDay 2用の手順書を、Claude Codeにコピペ。

> **自分：** 「docs/day2_dev_guide.md を読んで、Day 2の開発タスクを実行してください」

またターミナルがガーッと動く。今度は606行のコードが追加された。AI APIとの通信処理、画像のエンコード、レスポンスの解析……全部Claude Codeが書いた。

で、動作確認。

手元にあった渓流の写真をアプリに読み込ませたら――

**3つの英語フレーズが返ってきた。**

🟢 初級："The sound of the flowing water is so calming."
（流れる水の音はとても落ち着きます）

🟡 中級："The rocks are covered in vibrant green moss."
（岩は鮮やかな緑の苔で覆われています）

🔴 上級：（スクロールで表示）

【画像②: フレーズ結果画面 04_result_phrases.png ★ここにアップロード】

……感動した。

カメラで写真を撮るだけで、AIが画像の中身を理解して、それに関連する英語フレーズを生成している。しかも難易度別に色分けされている。緑が初級、黄が中級、赤が上級。

「これ、ちゃんとアプリっぽいじゃないか」と、深夜のテンションもあって少し興奮した。

---

## ただし、AIは完璧じゃなかった

Day 2で1つだけトラブルがあった。

最初にAIからのレスポンスを受け取ったとき、アプリがエラーを出した。原因は、**AIが返すJSONのキー名が、呼び出すたびに微妙に違う**という問題だった。

たとえば「english_phrase」と返すこともあれば「english」と返すこともある。プログラムは決められたキー名で受け取ろうとするから、違う名前で来ると「そんなデータないよ」とエラーになる。

これ、普通のプログラミングだったら自分では絶対に直せない。でもClaude Codeに「エラーが出た」と伝えたら、**30秒で修正した**。「複数のキー名に対応するフォールバック処理を追加しました」と。

……何を言っているのかはわからないけど、動いた。それが大事だ。

このエピソード、記事のネタとしてはむしろありがたい。Day 1のエラーゼロよりも「AIだって完璧じゃない。でもAIで直せる」というストーリーの方が面白い。

---

## Day 1-2の振り返り：自分がやったこと

2日分の作業を振り返ると、自分が実際にやったことはこれだけだ。

**Day 1:**
- ターミナルを開いた
- Claude Codeにコピペでプロンプトを渡した
- 「完了しました」と言われるまで待った

**Day 2:**
- OpenAIのサイトでAPIキーを作った（パスワード入力だけ自分）
- Claude Codeに再びコピペでプロンプトを渡した
- 渓流の写真でテストした

**自分が書いたコード：0行**
**AIが書いたコード：約6,500行（Day 1: 5,929行 + Day 2: 606行）**

繰り返すが、自分はコードを1行も書いていない。1行も読んでいない。それなのに、iPhoneシミュレータで動くアプリがあって、カメラで写真を撮ったらAIが英語フレーズを返してくるのだ。

しかもDay 1とDay 2を1日で前倒し完了してしまった。AI監督が出した「1週間スケジュール」を、初日で2日分クリアした計算になる。

---

## 正直な感想

ここまで来て、正直な感想を書く。

**嬉しい。でも不安。**

嬉しいのは、本当にアプリが動いているから。プログラミング未経験の自分が、チャットだけで。これは素直にすごいと思う。

不安なのは、**自分が何をしているのか全くわかっていない**から。

アプリは動いている。でも「なぜ動いているのか」は1ミリも理解していない。コードを見ても外国語みたいで読めない。エラーが出たら自分では何もできない。全部AIに聞くしかない。

これで大丈夫なのか？　この先、もっと複雑な機能を作るときに、AIだけで乗り越えられるのか？

わからない。でも、わからないまま進むのがこのプロジェクトだ。

Day 3では画面のデザインを整えて、お気に入り保存の機能を作る。だんだん「使えるアプリ」に近づいていくはずだ。

---

## 次回予告

Day 3-4では、SnapEnglishを「見た目もちゃんとしたアプリ」に仕上げていく。

- お気に入りのフレーズを保存できるようにする
- 撮影履歴を一覧で見られるようにする
- 画面のデザインを「App Storeに出せるレベル」に近づける

AIの指示通りに進めたら3日目にアプリが動いた。自分は何も理解していない。

次回の記事で、その続きを報告します。

---

**🔗 AI監督プロジェクト ― 1週間チャレンジ**
- #1 [Day 0 企画編 → Claude Opus 4.6がリリースされたので、全部AIに任せて1週間でiOSアプリを作ってみることにした](https://note.com/marumi_works/n/n00a946fe68da)
- **#2 Day 1-2 環境構築編（この記事）**
- #3 Day 3-4 実装編（近日公開）
- #4 Day 5-7 リリース編（近日公開）
- #5 収益報告編（近日公開）

---

*このプロジェクトの進捗はX（Twitter）でもリアルタイムで発信しています。*
*→ @marumi_works*

*ハッシュタグ： #AI監督プロジェクト #ClaudeOpus #AIでアプリ開発*

